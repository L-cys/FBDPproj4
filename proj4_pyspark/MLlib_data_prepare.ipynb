{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/chenyuanshan/temp/data/data/train_format1.csv')\n",
    "test = pd.read_csv('/Users/chenyuanshan/temp/data/data/test_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('/Users/chenyuanshan/temp/data/data/user_info_format1.csv')\n",
    "log = pd.read_csv('/Users/chenyuanshan/temp/data/data/user_log_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = pd.merge(test,info, on = \"user_id\", how = \"left\")\n",
    "test_info.to_csv(\"/Users/chenyuanshan/temp/data/data/test_info.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.merge(train, info, on = \"user_id\", how = \"left\")\n",
    "train_info.to_csv(\"/Users/chenyuanshan/temp/data/data/train_info.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want wo have the number of the user that have viewed the store, click, buy, and add to chart. Use spark sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = SparkConf.setAppName(\"spark_project\").master(\"local\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "#sc.setLogLevel('WARN')\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "#hive = HiveContext(sc)\n",
    "\n",
    "myspark = SparkSession.builder \\\n",
    "    .appName('spark_project') \\\n",
    "    .config('spark.executor.memory','2g') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = myspark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/chenyuanshan/temp/data/data/user_log_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = myspark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/chenyuanshan/temp/data/data/train_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- cat_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- brand_id: integer (nullable = true)\n",
      " |-- time_stamp: integer (nullable = true)\n",
      " |-- action_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log.createOrReplaceTempView(\"log\")\n",
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_count_user = myspark.sql(\"CREATE TABLE ViewUserSellerCount AS (SELECT user_id, seller_id, \\\n",
    "SUM(CASE WHEN action_type = 0 THEN 1 ELSE 0 END) AS click,\\\n",
    "SUM(CASE WHEN action_type = 1 THEN 1 ELSE 0 END) as add_chart,\\\n",
    "SUM(CASE WHEN action_type = 2 THEN 1 ELSE 0 END) AS buy, \\\n",
    "SUM(CASE WHEN action_type = 3 THEN 1 ELSE 0 END) AS favourite \\\n",
    "FROM log \\\n",
    "GROUP BY user_id, seller_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user_id=186568, seller_id=1337, click=10, add_chart=0, buy=0, favourite=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = myspark.sql(\"SELECT * FROM ViewUserSellerCount LIMIT 1\")\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_user_only = spark.sql(\"SELECT user_id, \\\n",
    "#COUNT(user_id) AS total_log, \\\n",
    "#SUM(CASE WHEN action_type = 0 THEN 1 ELSE 0 END) AS total_click,\\\n",
    "#SUM(CASE WHEN action_type = 1 THEN 1 ELSE 0 END) as total_add_chart,\\\n",
    "#SUM(CASE WHEN action_type = 2 THEN 1 ELSE 0 END) AS total_buy, \\\n",
    "#SUM(CASE WHEN action_type = 3 THEN 1 ELSE 0 END) AS total_favourite \\\n",
    "#FROM log \\\n",
    "#GROUP BY user_id\")\n",
    "log_user_only = myspark.sql(\"CREATE TABLE ViewUserCount AS (SELECT user_id, \\\n",
    "COUNT(user_id) AS total_log \\\n",
    "FROM log \\\n",
    "GROUP BY user_id)\")\n",
    "#log_user_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_seller_count = spark.sql(\"SELECT seller_id,\\\n",
    "#SUM(CASE WHEN action_type = 0 THEN 1 ELSE 0 END) AS seller_t_click,\\\n",
    "#SUM(CASE WHEN action_type = 1 THEN 1 ELSE 0 END) as seller_t_add_chart,\\\n",
    "#SUM(CASE WHEN action_type = 2 THEN 1 ELSE 0 END) AS seller_t_buy, \\\n",
    "#SUM(CASE WHEN action_type = 3 THEN 1 ELSE 0 END) AS seller_t_favourite \\\n",
    "#FROM log \\\n",
    "#GROUP BY seller_id\")\n",
    "log_seller_count = myspark.sql(\"CREATE TABLE ViewSellerCount AS (SELECT seller_id,\\\n",
    "SUM(CASE WHEN action_type = 0 THEN 1 ELSE 0 END) AS seller_t_click,\\\n",
    "SUM(CASE WHEN action_type = 2 THEN 1 ELSE 0 END) AS seller_t_buy \\\n",
    "FROM log \\\n",
    "GROUP BY seller_id)\")\n",
    "#log_seller_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_count_user.registerTempTable(\"ViewUserSellerCount\")\n",
    "#log_seller_count.registerTempTable(\"ViewSellerCount\")\n",
    "#log_user_only.registerTempTable(\"ViewUserCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_User_Seller = myspark.sql(\"CREATE TABLE ViewJoinOne AS (SELECT t1.user_id, t1.seller_id, t1.click, t1.add_chart, t1.buy, t1. favourite, t1.store_buy_rate, t2.total_log \\\n",
    "FROM ((SELECT user_id, seller_id, \\\n",
    "click, add_chart, buy, favourite, buy/click AS store_buy_rate \\\n",
    "from ViewUserSellerCount)t1 \\\n",
    "LEFT JOIN \\\n",
    "(SELECT user_id, total_log FROM ViewUserCount)t2 \\\n",
    "ON t1.user_id = t2.user_id))\")\n",
    "#train_User_Seller.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_User_Seller.registerTempTable(\"ViewJoinOne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seller = myspark.sql(\"SELECT t1.user_id, t1.seller_id, t1.total_log, t1.click, t1.add_chart, t1.buy, t1. favourite, t1.store_buy_rate, t2.store_rate \\\n",
    "FROM (SELECT user_id, seller_id, click, add_chart, buy, favourite, store_buy_rate, total_log \\\n",
    "FROM ViewJoinOne)t1 \\\n",
    "LEFT JOIN \\\n",
    "(SELECT seller_id, seller_t_buy/seller_t_click AS store_rate \\\n",
    "FROM ViewSellerCount)t2 \\\n",
    "ON t1.seller_id = t2.seller_id\")\n",
    "# Watch out! here to stop!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seller.repartition(1).write.format(\"com.databricks.spark.csv\").options(header='true',inferschema='true').save('/Users/chenyuanshan/temp/data/data/tempsave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seller = myspark.sql(\"CREATE TABLE last AS (SELECT t1.user_id, t1.seller_id, t1.total_log, t1.click, t1.add_chart, t1.buy, t1. favourite, t1.store_buy_rate, t2.store_rate \\\n",
    "FROM (SELECT user_id, seller_id, click, add_chart, buy, favourite, store_buy_rate, total_log \\\n",
    "FROM ViewJoinOne)t1 \\\n",
    "LEFT JOIN \\\n",
    "(SELECT seller_id, seller_t_buy/seller_t_click AS store_rate \\\n",
    "FROM ViewSellerCount)t2 \\\n",
    "ON t1.seller_id = t2.seller_id)\")\n",
    "#train_seller.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- age_range: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.registerTempTable(\"train\")\n",
    "#train_seller.registerTempTable(\"last\")\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It finally export sucessfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainMatrix.registerTempTable(\"outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use temp view, don't use HIVE table and export in sql way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"phase one, merge needed later\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of file too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- total_log: long (nullable = true)\n",
      " |-- click: long (nullable = true)\n",
      " |-- add_chart: long (nullable = true)\n",
      " |-- buy: long (nullable = true)\n",
      " |-- favourite: long (nullable = true)\n",
      " |-- store_buy_rate: double (nullable = true)\n",
      " |-- store_rate: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainMatrix.createOrReplaceTempView(\"smallMatrix\")\n",
    "trainMatrix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_null = pd.read_csv('/Users/chenyuanshan/temp/data/data/featureMatrix/train.csv',header = None)\n",
    "test_null = pd.read_csv('/Users/chenyuanshan/temp/data/data/testMatrix/test.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2      1253\n",
       "3      3711\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9     29873\n",
       "10        0\n",
       "11        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_null.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fill = train_null.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fill.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2       1325\n",
       "3       3834\n",
       "4          0\n",
       "5          0\n",
       "6          0\n",
       "7          0\n",
       "8          0\n",
       "9      29535\n",
       "10         0\n",
       "11    261477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fill = test_null.fillna(method='bfill')\n",
    "test_fill = test_fill.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "5          0\n",
       "6          0\n",
       "7          0\n",
       "8          0\n",
       "9          0\n",
       "10         0\n",
       "11    261477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fill.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fill.to_csv('/Users/chenyuanshan/temp/data/data/featureMatrix/trainfill.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fill.to_csv('/Users/chenyuanshan/temp/data/data/testMatrix/testfill.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header = pd.read_csv('/Users/chenyuanshan/temp/data/data/featureMatrix/featureMatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header = add_header.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           0\n",
       "merchant_id       0\n",
       "age_range         0\n",
       "gender            0\n",
       "total_log         0\n",
       "click             0\n",
       "add_chart         0\n",
       "buy               0\n",
       "favourite         0\n",
       "store_buy_rate    0\n",
       "store_rate        0\n",
       "label             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_header.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header.to_csv('/Users/chenyuanshan/temp/data/data/featureMatrix/withHeader.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header = pd.read_csv('/Users/chenyuanshan/temp/data/data/testMatrix/testMatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header = add_header.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_header.to_csv('/Users/chenyuanshan/temp/data/data/testMatrix/withHeader.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
