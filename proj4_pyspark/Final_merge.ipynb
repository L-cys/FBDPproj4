{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspark = SparkSession.builder \\\n",
    "    .appName('spark_project') \\\n",
    "    .config('spark.executor.memory','2g') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = myspark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/chenyuanshan/temp/data/data/tempsave/tempsave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = myspark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/chenyuanshan/temp/data/data/train_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = myspark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/chenyuanshan/temp/data/data/test_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- prob: string (nullable = true)\n",
      " |-- age_range: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      " |-- total_log: integer (nullable = true)\n",
      " |-- click: integer (nullable = true)\n",
      " |-- add_chart: integer (nullable = true)\n",
      " |-- buy: integer (nullable = true)\n",
      " |-- favourite: integer (nullable = true)\n",
      " |-- store_buy_rate: double (nullable = true)\n",
      " |-- store_rate: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- age_range: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.registerTempTable(\"features\")\n",
    "#df_train.registerTempTable(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.registerTempTable(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = myspark.sql(\"SELECT t1.user_id, t1.merchant_id, t1.age_range, t1.gender, t2.total_log, t2.click, t2.add_chart, \\\n",
    "t2.buy, t2.favourite, t2.store_buy_rate, t2.store_rate, t1.label FROM \\\n",
    "(SELECT * FROM train)t1 \\\n",
    "LEFT JOIN \\\n",
    "(SELECT * FROM features)t2 \\\n",
    "ON t1.user_id = t2.user_id AND t1.merchant_id = t2.seller_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = myspark.sql(\"SELECT t1.user_id, t1.merchant_id, t1.age_range, t1.gender, t2.total_log, t2.click, t2.add_chart, \\\n",
    "t2.buy, t2.favourite, t2.store_buy_rate, t2.store_rate, t1.prob FROM \\\n",
    "(SELECT * FROM test)t1 \\\n",
    "LEFT JOIN \\\n",
    "(SELECT * FROM features)t2 \\\n",
    "ON t1.user_id = t2.user_id AND t1.merchant_id = t2.seller_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.repartition(1).write.format(\"com.databricks.spark.csv\").options(header='true',inferschema='true').save('/Users/chenyuanshan/temp/data/data/featureMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.repartition(1).write.format(\"com.databricks.spark.csv\").options(header='true',inferschema='true').save('/Users/chenyuanshan/temp/data/data/testMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
