{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('randomForest').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfo = spark.read.csv('/Users/chenyuanshan/temp/data/data/featureMatrix/withHeader.csv', inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfoAssembler = VectorAssembler(inputCols=['age_range','gender','total_log','click','add_chart','buy','favourite', \\\n",
    "                                            'store_buy_rate', 'store_rate'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfo = dfInfoAssembler.transform(dfInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+-----+\n",
      "|features                                                                 |label|\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "|[6.0,0.0,62.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.08940820834786653]    |0    |\n",
      "|[3.0,0.0,591.0,16.0,0.0,1.0,0.0,0.0625,0.09346991037131884]              |0    |\n",
      "|[6.0,1.0,537.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.12137006701414745]   |0    |\n",
      "|[0.0,0.0,49.0,3.0,0.0,2.0,0.0,0.6666666666666666,0.07458405048766495]    |0    |\n",
      "|[4.0,1.0,182.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.12729948491537896]   |0    |\n",
      "|[4.0,0.0,149.0,2.0,0.0,1.0,0.0,0.5,0.13248090925235306]                  |0    |\n",
      "|[6.0,0.0,457.0,0.0,0.0,1.0,0.0,0.5,0.1026058631921824]                   |0    |\n",
      "|[2.0,0.0,128.0,7.0,0.0,1.0,0.0,0.14285714285714285,0.06504520137703268]  |0    |\n",
      "|[6.0,1.0,274.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.13646485199831074]   |0    |\n",
      "|[4.0,0.0,307.0,55.0,0.0,3.0,0.0,0.054545454545454536,0.05528939030986786]|0    |\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfInfo.select(['features', 'label']).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfoModel = dfInfo.select(['features', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,test = dfInfoModel.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = RandomForestClassifier(labelCol='label').fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRslt = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = testRslt.filter(testRslt['prediction'] == 1).filter(testRslt['label'] == 1).count()\n",
    "FN = testRslt.filter(testRslt['prediction'] == 0).filter(testRslt['label'] == 1).count()\n",
    "TN = testRslt.filter(testRslt['prediction'] == 0).filter(testRslt['label'] == 0).count()\n",
    "FP = testRslt.filter(testRslt['prediction'] == 1).filter(testRslt['label'] == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396709323583181\n"
     ]
    }
   ],
   "source": [
    "acc =(TP+TN)/(TP+TN+FP+FN)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0\n"
     ]
    }
   ],
   "source": [
    "recall = TP/(TP+TN)\n",
    "print(recall, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy').evaluate(testRslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc[0.9396709323583181], auc[0.619954063732903]\n"
     ]
    }
   ],
   "source": [
    "auc = BinaryClassificationEvaluator(labelCol='label').evaluate(testRslt)\n",
    "print('acc[{}], auc[{}]'.format(acc2,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = \\\n",
    "spark.read.csv('/Users/chenyuanshan/temp/data/data/testMatrix/withHeader.csv', inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAssembler = VectorAssembler(inputCols=['age_range','gender','total_log','click','add_chart','buy','favourite', \\\n",
    "                                            'store_buy_rate', 'store_rate'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = dfInfoAssembler.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeName = StringIndexer(inputCol='prob', outputCol='label').fit(dftest)\n",
    "testFinal = changeName.transform(dfInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+-----+\n",
      "|features                                                                 |label|\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "|[6.0,0.0,62.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.08940820834786653]    |0    |\n",
      "|[3.0,0.0,591.0,16.0,0.0,1.0,0.0,0.0625,0.09346991037131884]              |0    |\n",
      "|[6.0,1.0,537.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.12137006701414745]   |0    |\n",
      "|[0.0,0.0,49.0,3.0,0.0,2.0,0.0,0.6666666666666666,0.07458405048766495]    |0    |\n",
      "|[4.0,1.0,182.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.12729948491537896]   |0    |\n",
      "|[4.0,0.0,149.0,2.0,0.0,1.0,0.0,0.5,0.13248090925235306]                  |0    |\n",
      "|[6.0,0.0,457.0,0.0,0.0,1.0,0.0,0.5,0.1026058631921824]                   |0    |\n",
      "|[2.0,0.0,128.0,7.0,0.0,1.0,0.0,0.14285714285714285,0.06504520137703268]  |0    |\n",
      "|[6.0,1.0,274.0,3.0,0.0,1.0,0.0,0.3333333333333333,0.13646485199831074]   |0    |\n",
      "|[4.0,0.0,307.0,55.0,0.0,3.0,0.0,0.054545454545454536,0.05528939030986786]|0    |\n",
      "+-------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testFinal.select(['features', 'label']).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOutput = rfModel.transform(testFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15952"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testOutput.filter(testOutput['label'] == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = testOutput.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- age_range: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      " |-- total_log: integer (nullable = true)\n",
      " |-- click: integer (nullable = true)\n",
      " |-- add_chart: integer (nullable = true)\n",
      " |-- buy: integer (nullable = true)\n",
      " |-- favourite: integer (nullable = true)\n",
      " |-- store_buy_rate: double (nullable = true)\n",
      " |-- store_rate: double (nullable = true)\n",
      " |-- prob: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = testData[['user_id', 'merchant_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'merchant_id', 'age_range', 'gender', 'total_log', 'click', 'add_chart', 'buy', 'favourite', 'store_buy_rate', 'store_rate', 'label', 'features', 'rawPrediction', 'probability', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "colums = testOutput.columns\n",
    "print(colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = testOutput.select(['user_id','merchant_id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.repartition(1).write.format(\"com.databricks.spark.csv\") \\\n",
    ".options(header='true',inferschema='true').save('/Users/chenyuanshan/temp/data/RamdonForestOut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tread = spark.read.csv('/Users/chenyuanshan/temp/data/RamdonForestOut.csv', inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=464, merchant_id=4718, label=0),\n",
       " Row(user_id=867, merchant_id=3152, label=0),\n",
       " Row(user_id=1882, merchant_id=4377, label=0),\n",
       " Row(user_id=2450, merchant_id=2760, label=0),\n",
       " Row(user_id=2766, merchant_id=3885, label=0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tread.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_tread = tread.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         user_id  merchant_id  label\n",
       "0           464         4718      0\n",
       "1           867         3152      0\n",
       "2          1882         4377      0\n",
       "3          2450         2760      0\n",
       "4          2766         3885      0\n",
       "...         ...          ...    ...\n",
       "260859   421807         3057      0\n",
       "260860   422078         3374      0\n",
       "260861   422097         3609      0\n",
       "260862   422648         4502      0\n",
       "260863   423267         3578      0\n",
       "\n",
       "[260864 rows x 3 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_tread.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_tread.to_csv('/Users/chenyuanshan/temp/data/data/output/RandomForestOutput.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
